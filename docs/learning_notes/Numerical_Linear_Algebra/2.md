
> date: 2021-10-29


## 一、Gram–Schmidt 正交化

我们接下来所有的讨论均是基于实数域或复数域的，我们用 $\mathbb K$ 来代表实数域 $\mathbb R$ 或复数域 $\mathbb C$。

$\textbf{Definition(inner product).}$ 给定 $\mathbb C^d$上的向量空间 $V$，维度是有限维，则 $V$ 上的一个 **内积（inner product）** 是一个映射：$(x, y) \mapsto \langle x, y \rangle \in \mathbb C, \text{from } V \times V \text{ to } \mathbb C$，满足
$$
\left\{\begin{aligned}
&\forall v \in V, \langle v, v \rangle \geq 0; \\
&\langle v, v \rangle = 0 \Longleftrightarrow v = 0 \in V; \\
&\langle a_1v_1+a_2v_2, w \rangle = a_1\langle v_1, w \rangle + a_2\langle v_2, w \rangle, a_1, a_2 \in \mathbb C, v_1, v_2, w \in V; \\
&\langle v, w \rangle = \overline{\langle w, v \rangle}.
\end{aligned}
\right.
$$
$\textbf{Remark.}$ 

- $\|v\| := \sqrt{\langle v, v \rangle}$.
- $|\langle u, v \rangle| \leq \|u\| \cdot \|v\|.$（Cauchy–Schwarz inequality）
- 给定一个范数 $\|\cdot\|$，存在一个内积 $\langle \cdot, \cdot \rangle$，使得 $\|v\| := \sqrt{\langle v, v \rangle}$ $\Longleftrightarrow$ $\|u+v\|^2 + \|u-v\|^2 = 2\|u\|^2 + 2\|v\|^2.$（即平行四边形对角线平方和等于四条边的平方和）
- 对矩阵 $X, Y \in \mathbb C^{n \times n}$，$\langle X, Y\rangle = \text{tr}(X^*Y) = \sum_{i, j}\bar x_{ij} y_{ij}.$ 

<br>

考虑带有（be endowed with）标量内积（scalar product）$\langle x, y \rangle = \sum_{i=1}^n x_iy_i, \text{if }\mathbb K = \mathbb R$，或Hermitian内积 $\langle x, y \rangle = \sum_{i=1}^n x_i\bar{y_i}, \text{if }\mathbb K = \mathbb C$ 的向量空间 $\mathbb K^d$， **Gram-Schmidt正交化（Gram-Schmidt Orthonormalization Process）** 是基于一组 $\mathbb K^d$中的线性独立向量（linearly independent），来构建一组 $\mathbb K^n$中的正交向量的过程。这个算法在数值线性代数中十分常用。

$\textbf{Remark.}$ $(x_1, \cdots, x_n)$ 线性无关（Linearly independent），即表示对任意的 $a_i \in \mathbb K, i = 1, \cdots, n$，$\sum_i a_ix_i = 0$ 当且仅当 $a_1 = \cdots = a_n = 0$。

$\textbf{Remark.}$ 向量组 $(y_1, \cdots, y_n)$ 是一族（单位）正交向量（orthogonal family），即表示对任意的 $i \neq j$，有 $\|y_i\|=1, \langle y_i, y_j \rangle = 0$。

$\textbf{Theorem 2.1.1 (Gram-Schmidt).}$ 取 $(x_1, \cdots, x_n)$ 为 $\mathbb K^d$中一族线性无关的向量。存在一族（单位）正交向量 $(y_1, \cdots, y_n)$，对任意满足  $1 \leq p \leq n$ 的 $p$，使得
$$
\text{span}\{y_1, \cdots, y_p\} = \text{span}\{x_1, \cdots, x_p\},
$$
其中 $\text{span}\{\cdots\}$ 代表向量张成的空间，即
$$
\text{span}\{v_1, \cdots, v_n\} = \{\sum_{i=1}^n a_iv_i | a_i \in \mathbb K, i = 1, \cdots, n \}.
$$
如果 $\mathbb K = \mathbb R$，this family is unique up to a change of sign of each vector $y_p$；

如果 $\mathbb K = \mathbb C$，this family is unique up to a multiplicative factor of unit modulus for each vector $y_p$.

$\textit{Proof.}$ 待补 $\square$ 



## 二、Matrices

$\textbf{Definition 2.2.1.}$ 矩阵 $A$ 是一个矩形数组 $(a_{ij})_{1\leq i\leq n, 1 \leq j \leq p}$，其中 $a_{ij} \in \mathbb K$ 是第 $i$ 行、第 $j$ 列的输入，即有
$$
A=\left(\begin{array}{ccc}
a_{1,1} & \ldots & a_{1, p} \\
\vdots & & \vdots \\
a_{n, 1} & \ldots & a_{n, p}
\end{array}\right).
$$
我们用记号 $\mathcal M_{n, p} (\mathbb K)$ 表示，所有的输入元素来自 $\mathbb K$ 的 $n \times p$ 矩阵（$n$ 行 $j$ 列）构成的集合；用记号 $\mathcal M_{n} (\mathbb K)$ 表示，所有的输入元素来自 $\mathbb K$ 的 $n \times n$ 矩阵构成的集合。

$\textbf{Remark 2.2.1.}$ Matrix multiplication is associative, i.e., $(MN)P = M(NP)$. However, the multiplication is usually not commutative, i.e., $AB\neq BA$.

$\textbf{Definition 2.2.4.}$ 对任意的矩阵 $A=\left(a_{i, j}\right)_{1 \leq i \leq n, 1 \leq j \leq p} \in \mathcal{M}_{n, p}(\mathbb{K})$，我们用 $A^t$（或 $A^T$）表示矩阵 $A$ 的 **转置（transpose）** ，其定义为
$$
A^t=\left(a_{j, i}\right)_{1 \leq i \leq n, 1 \leq j \leq p},
$$
其中 $A^t= \in \mathcal{M}_{p, n}(\mathbb{K})$。如果 $A$ 为**方阵（square matrix）**，即 $n = p$，且有 $A^t = A$ ，则称 $A$ 为 **对称矩阵（Symmetric matrix）** 。

$\textbf{Definition 2.2.5.}$ 矩阵 $A \in \mathcal M_n(\mathbb K)$ 是 **可逆的（invertible）** ，或者说 **非奇异的（nonsingular）** ，如果存在一个矩阵 $B \in \mathcal M_n(\mathbb K)$，使得 $AB = BA = I_n$。此时我们称 $B = A^{-1}$ 是 $A$ 的逆矩阵（inverse matrix）。

$\textbf{Definition.}$ 对向量空间 $V$，我们称  $A\sub V$  是 **子空间（subspace）** ，当且仅当 $\forall x, y \in A, \lambda \in \mathbb K$，有 $x + \lambda y \in A$，即 $A$ 对加法和数乘都是封闭的。

$\textbf{Definition.}$ **Dimension** of subspace of $\mathbb K^d$, is the number of elements in a spanning linearly independent set of vectors(i.e., a basis).

$\textbf{Definition.}$ 矩阵 $A \in \mathcal M_{n, p}(\mathbb K)$ 的 **核空间（kernel space）** 或 **零空间（null space）** 为
$$
\text{Ker}(A) = \{x \in \mathbb K^p |Ax = 0\} \sub \mathbb K^p,
$$
即 $\text{Ker}(A)$ 是 $\mathbb K^p$ 的子空间；矩阵 $A$ 的 **image** 或 **range** 为
$$
\text{Im}(A) = \{Ax|x\in\mathbb K^p\} \sub \mathbb K^n,
$$
即 $\text{Im}(A)$ 是 $\mathbb K^n$ 的子空间；

矩阵 $A$ 的 **秩（rank）** 为
$$
\text{rk}(A) = \dim(\text{Im}(A)),
$$
其中 $\dim(\cdot)$ 表示维度。矩阵 $A$ 的 **列空间（column space）** 为
$$
\text{Col}(A) = \text{span}\{a_1, \cdots, a_p\} = \text{Im}(A), \quad A = [a_1|\cdots|a_p],
$$
**行空间（row space）** 为
$$
\text{Row}(A) = \text{Im}(A^T).
$$
$\textbf{Remark.}$ 取子空间 $A \sub \mathbb K^d$，如果 $\{v_1, \cdots, v_k\}, \{w_1, \cdots, w_l\}$ 是 $A$ 的两个基向量集合，则 $k = l$。

$\textit{Proof.}$ 注意到 $\text{span}\{v_1, \cdots, v_k\} = A$，且 $\{w_1, \cdots, w_l\}$ 是线性独立的向量组，因此必有 $k \geq l$；同理可推出 $l \geq k$，即得 $k = l$。$\square$

$\textbf{Remark.}$ 

$\textbf{Lemma 2.2.1.}$ 对任意矩阵 $A \in \mathcal M_n(\mathbb K)$ ，TFAE（The Following are All Equivalent）：

1. $A$ 是可逆的；
2. $\text{Ker}(A) = \{0\}$；
3. $\text{Im}(A) = \mathbb K^n$；
4. 存在矩阵 $B \in \mathcal M_n(\mathbb K)$ 使得 $AB = I_n$；
5. 存在矩阵 $B \in \mathcal M_n(\mathbb K)$ 使得 $BA = I_n$。

$\textit{Proof.}$ 待补 $\square$

$\textbf{Lemma 2.2.2.}$ 取可逆矩阵 $A, B \in \mathcal M_n(\mathbb K)$，则有 $(AB)^{-1} = B^{-1}A^{-1}$。



### （1）迹和行列式

在这一小节中，所有矩阵均为方阵，即来自 $\mathcal M_n(\mathbb K)$。

$\textbf{Definition 2.2.6.}$ 矩阵 $A = (a_{ij})_{1 \leq i,j\leq n}$ 的 **迹（trace）** 是其对角线元素的和：
$$
\text{tr}(A) = \sum_{i=1}^n a_{ii}.
$$
$\textbf{Lemma 2.2.3.}$ 对方阵 $A, B \in \mathcal M_n(\mathbb K)$，有 $\text{tr}(AB) = \text{tr}(BA)$。

$\textbf{Definition 2.2.7.}$ 我们称类似 $(1, 2, \cdots, n), (2, 1, \cdots, n), (n, \cdots, 1)$ 是 $n$ 的一个 **排列（permutation）** 。我们用 $\mathcal S_n$ 表示所有 $n$ 的排列构成的集合。我们用 $\varepsilon (\sigma)$ 表示某一排列 $\sigma$ 的符号，取值为 $1$ 或 $-1$，具体为
$$
\varepsilon(\sigma)=(-1)^{p(\sigma)} \quad \text { with } \quad p(\sigma)=\sum_{1 \leq i \leq j \leq n} \operatorname{Inv}_{\sigma}(i, j),
$$
其中 $\operatorname{Inv}_{\sigma}(i, j)$ 表示 $i$ 和 $j$ 在排列 $\sigma$ 中的顺序是否被颠倒了，即对 $i \leq j$，有
$$
\operatorname{Inv}_{\sigma}(i, j)= 
\begin{cases}
0 & \text { if } \sigma(i) \leq \sigma(j) \\ 
1 & \text { if } \sigma(i)>\sigma(j)
\end{cases}.
$$
$\textbf{Definition 2.2.8.}$ 方阵 $A = (a_{ij})_{1 \leq i,j\leq n} \in \mathcal M_n(\mathbb K)$ 的 **行列式（determinant）** 为
$$
\det A = \sum_{\sigma \in \mathcal S_n}\varepsilon(\sigma)\prod_{i=1}^n a_{i, \sigma(i)}.
$$
$\textbf{Lemma 2.2.4.}$ 对方阵 $A, B \in \mathcal M_n(\mathbb K)$，我们有：

1. $\det (AB) = (\det A)(\det B) = \det(BA)$；
2. $\det A^t = \det A$；
3. $A$ 是可逆的，当且仅当 $\det A \neq 0$。
4. 如果 $A$ 是可逆的，则有 $\det A \det A^{-1} = 1$，因为 $A A^{-1} = I$，由性质1可得。



### （2）一些特殊矩阵

$\textbf{Definition 2.2.9.}$ 我们称矩阵 $A = (a_{ij})_{1 \leq i,j\leq n} \in \mathcal M_n(\mathbb K)$ 是 **对角矩阵（diagonal matrix）** ，如果对 $i \neq j$ 有 $a_{ij} = 0$。通常我们用 $\text{diag}(a_{11}, \cdots, a_{nn})$ 来表示对角矩阵。

$\textbf{Definition 2.2.10.}$ 取矩阵 $T = (t_{ij})_{1 \leq i \leq n, 1 \leq j\leq p} \in \mathcal M_{n, p}(\mathbb K)$。如果对任意的 $i > j$ 都有 $t_{ij} = 0$，则我们称它是 **上三角矩阵（upper triangular matrix）** ； 如果对任意的 $i < j$ 都有 $t_{ij} = 0$，则我们称它是 **下三角矩阵（upper triangular matrix）** 。

$\textbf{Lemma 2.2.5.}$ 取矩阵 $T  \in \mathcal M_{n}(\mathbb K)$ 是一个下三角矩阵（上三角矩阵）。如果它可逆，则它的逆矩阵也是下三角矩阵（上三角矩阵），且对角线元素为 $T$ 对角线的倒数。取矩阵 $T'  \in \mathcal M_{n}(\mathbb K)$ 是一个下三角矩阵（上三角矩阵），则乘积 $TT'$ 也是下三角矩阵（上三角矩阵），对角线元素为 $T$ 的对角线乘以 $T'$ 的对角线。

$\textbf{Definition 2.2.11.}$ 取矩阵 $A = (a_{ij})_{1 \leq i, j \leq n} \in \mathcal M_n(\mathbb C)$，它的 **伴随矩阵（adjoint matrix）** 被定义为 $A$ 的共轭转置，即 $A^* = \bar A^t = (\bar a_{ji})_{1 \leq i,j\leq n} \in \mathcal M_n(\mathbb C)$。$A^*$ 有时也写作 $A^H$。

$\textbf{Definition 2.2.12.}$ 取矩阵 $A = (a_{ij})_{1 \leq i, j \leq n} \in \mathcal M_n(\mathbb C)$，则我们称

1. $A$ 是 **自伴随的（self-adjoint）** ，或是 **Hermitian的** ，如果有 $A = A^*$；
2. $A$ 是 **酉矩阵（unitary matrix）** ，如果有 $A^{-1} = A^*$；
3. $A$ 是 **正规矩阵（normal matrix）** ，如果有 $AA^* = A^*A$。

$\textbf{Definition 2.2.13.}$ 取矩阵 $A = (a_{ij})_{1 \leq i, j \leq n} \in \mathcal M_n(\mathbb R)$，则我们称

1. $A$ 是 **自伴随的（self-adjoint）** ，或是 **对称的（symmetric）** ，如果有 $A = A^t$；
2. $A$ 是 **酉矩阵（unitary matrix）** 或 **正交矩阵（orthogonal matrix）** ，如果有 $A^{-1} = A^t$；
3. $A$ 是 **正规矩阵（normal matrix）** ，如果有 $AA^t = A^tA$。

$\textbf{Remark.}$ 酉矩阵的行列式值为1或-1。

$\textit{Proof.}$ 我们有 $\det(AA^H) = \det(AA^{-1}) = 1$，即有 $\det A \det A^H = (\det A)^2 = 1$. $\square$

$\textbf{Remark.}$ 显然，Hermitian矩阵是正规矩阵。

$\textbf{Remark.}$ 

- 对 $x, y \in \mathbb C^d$，$\langle x, y \rangle = x^T \bar y$；（这里对复向量的内积定义似乎还有 $\langle x, y \rangle = x^* \cdot y = x^*y^T$）
- $\langle Au, v \rangle = \langle u, A^*v\rangle$，其中 $A^*$ 是矩阵 $A$ 的共轭转置。

$\textbf{Remark.}$ 上三角矩阵/下三角矩阵的行列式为对角线的乘积。



### （3）矩阵的行和列

矩阵 $A \in \mathcal M_{n, p}(\mathbb C)$ 可以按列 $c_j \in \mathbb C^n$ 被定义为
$$
A = [c_1 | \dots| c_p],
$$
或按行 $\ell_i \in \mathcal M_{1, p}(\mathbb C)$ 被定义为
$$
A=\left[\begin{matrix}
\ell_{1} \\
- \\
\vdots \\
- \\
\ell_{n}
\end{matrix}\right].
$$
$c_j^* \in \mathcal M_{1, n}(\mathbb C)$ 是 $c_j$ 的共轭转置，是一个行向量；$\ell_i^* \in \mathbb C^p$ 是 $\ell_i$ 的共轭转置，是一个列向量。我们有
$$
A^*=\left[\begin{matrix}
c_{1}^* \\
- \\
\vdots \\
- \\
c_{p}^*
\end{matrix}\right]
=
[\ell_1^* | \dots|\ell_n^*].
$$
对矩阵 $X \in \mathcal M_{m,n}(\mathbb C)$，我们有
$$
XA = X[c_1 | \dots| c_p] = [Xc_1 | \dots| Xc_p].
$$
类似地，对矩阵 $X \in \mathcal M_{p, m}(\mathbb C)$，我们有
$$
AX = \left[\begin{matrix}
\ell_{1} \\
- \\
\vdots \\
- \\
\ell_{n}
\end{matrix}\right]X
=
\left[\begin{matrix}
\ell_{1}X \\
- \\
\vdots \\
- \\
\ell_{n}X
\end{matrix}\right],
$$
特别地，对任意列向量 $x \in \mathbb C^p$，我们有
$$
Ax = \left[\begin{matrix}
\ell_{1}x \\
- \\
\vdots \\
- \\
\ell_{n}x
\end{matrix}\right] = \sum_{i=1}^p x_ic_i.
$$
给定列向量 $u_1, \cdots,u_m \in \mathbb C^n$，列向量 $v_1, \cdots, v_m \in \mathbb C^p$，那我们可以定义来自 $\mathcal M_{n, p}(\mathbb C)$ 的乘积矩阵
$$
UV^* = \sum_{i=1}^m u_iv_i^* = [u_1 | \dots| u_m]\left[\begin{matrix}
v_{1}^* \\
- \\
\vdots \\
- \\
v_{m}^*
\end{matrix}\right],
$$
其中
$$
U = [u_1 | \dots| u_m] \in \mathcal M_{n, m}(\mathbb C),\\
V = [v_1 | \dots| v_m] \in \mathcal M_{p, m}(\mathbb C).
$$


### （4）矩阵的行列变换

取矩阵 $A \in \mathcal M_{n, p}(\mathbb K)$。

- 每行乘标量：通过对 $A$ 左乘一个对角矩阵 $\text{diag}(a_1. \cdots, a_n), a_i \in \mathbb K$。即 $\text{diag}(a_1. \cdots, a_n) A$ 实际相当于对 $A$ 的第 $i$ 行乘以标量 $a_i$。
- 每列乘标量：通过对 $A$ 右乘一个对角矩阵 $\text{diag}(a_1. \cdots, a_p), a_i \in \mathbb K$。即 $A\text{diag}(a_1. \cdots, a_p)$ 实际相当于对 $A$ 的第 $j$ 列乘以标量 $a_j$。

- 要交换矩阵 $A$ 的第 $l_1$ 行和第 $l_2$ 行，我们可以通过对 $A$ 左乘一个 **置换矩阵（permutation matrix）** $P(l_1, l_2)$，即 $P(l_1, l_2) A$ 实际相当于对 $A$ 的第 $l_1$ 行和第 $l_2$ 行做交换。置换矩阵 $P(l_1, l_2)$ 是一个方阵，它满足：

  1. $$
     p_{ii} = \left\{
     \begin{aligned}
     0, & \text{ if } i \in \{l_1, l_2\},\\
     1, & \text{ otherwise;}
     \end{aligned}
     \right.
     $$

  2. 对 $i \neq j$，有
     $$
     p_{ij} = \left\{
     \begin{aligned}
     1, & \text{ if } (i, j) \in \{(l_1, l_2), (l_2, l_1)\},\\
     0, & \text{ otherwise.}
     \end{aligned}
     \right.
     $$

  例如，有
  $$
  P(1, 2) = 
  \left[
  \begin{matrix}
  0 & 1 & 0\\
  1 & 0 & 0\\
  0 & 0 & 1
  \end{matrix}
  \right].
  $$
  实际上，置换矩阵 $P(l_1, l_2)$ 即为将单位矩阵 $I_n$ 的第 $i$ 行和第 $j$ 列做交换后得到的矩阵。

- 要交换矩阵 $A$ 的第 $c_1$ 列和第 $c_2$ 列，我们可以通过对 $A$ 右乘一个置换矩阵（permutation matrix）$P(c_1, c_2)$，即 $AP(c_1, c_2)$ 实际相当于对 $A$ 的第 $c_1$ 列和第 $c_2$ 列做交换。



### （5）分块矩阵

$\textbf{Lemma 2.2.6.}$ 取来自 $\mathcal M_{n_I,n_J}(\mathbb K)$ 的两个分块矩阵 $A = (A_{I,J})_{1 \leq I,J \leq p}, B= (B_{I,J})_{1 \leq I,J \leq p}$。则有矩阵乘积 $C=AB$ 也可以被写为分块矩阵的形式，即有
$$
C_{I,J} = \sum_{K=1}^p A_{I,K}B_{K,J}, 
$$
其中 $1 \leq I, J \leq p,$，且 $C_{I,J}$ 和 $A_{I,J}, B_{I,J}$ 的维度相同。

$\textbf{Remark.}$ 分块矩阵的对角线是方阵。

<br>

上述引理表明分块矩阵满足矩阵的乘法规则，但分块矩阵的运算并不满足大多的其他矩阵运算法则，如，特别指出，there is no block determinant rule. 事实上，对分块矩阵，我们有
$$
\det \left[
\begin{matrix}
A & C\\
0 & B
\end{matrix}
\right]
= \det A \det B.
$$


## 三、矩阵的谱理论

在接下来的讨论中，除非指明，否则我们假设所有矩阵都是复方阵，即来自 $\mathcal M_n(\mathbb K)$。

$\textbf{Definition 2.3.1.}$ 取矩阵 $A \in \mathcal M_n(\mathbb C)$，我们用记号 $P_A(\lambda)$ 来表示它的 **特征多项式（characteristic polynomial）** ，它被定义在 $\mathbb C$ 上，具体为
$$
P_A(\lambda) = \det(A - \lambda I).
$$
它是一个 $n$ 阶的多项式，因此它有 $n$ 个来自 $\mathbb C$ 的根，我们称这些根为 $A$ 的 **特征值（eigenvalue）** 。特征值的 **代数重数（algebraic multiplicity）** 是其做为特征多项式的根的重数。我们称一个非零向量 $x \in \mathbb C^n$ 是关于矩阵 $A$ 特征值 $\lambda$ 所对应的一个 **特征向量（eigenvector）** ，如果它满足 $Ax = \lambda x$。我们有时会用记号 $\lambda(A)$ 表示矩阵 $A$ 的一个特征值。矩阵 $A$ 所有特征值构成的集合是矩阵 $A$ 的 **谱（spectrum）** ，用记号 $\sigma(A)$ 表示。

$\textbf{Definition 2.3.2.}$ 取矩阵 $A \in \mathcal M_n(\mathbb C)$，我们把矩阵 $A$ 特征值中最大的模（modulus）称为矩阵 $A$ 的 **谱半径（spectrum radius）** ，用记号 $\varrho(A)$ 表示，即有 $\varrho(A) = \{|\lambda_i|, \text{where }\lambda_i \in \sigma(A), i = 1,\cdots, n\}$。

> 这里特别指出，对复数 $\lambda \in \mathbb C$ 而言，$|\lambda|^2 = \lambda \cdot \bar \lambda$，而 $\lambda^2 = \lambda \cdot \lambda$，注意区分。

$\textbf{Remark.}$ 

1. 如果 $\lambda$ 是矩阵 $A$ 的一个特征值，那么总存在一个对应的特征向量 $x$，即存在来自 $\mathbb C^n$ 的非零向量 $x$ 使得 $Ax = \lambda x$，$x$ 不唯一。

   诚然，$P_A(\lambda) = 0$ 代表矩阵 $(A - \lambda I)$ 是奇异的。特别地，它的核空间并没有缩减为$0$向量，即 $\text{Ker}(A - \lambda I) \neq \{0\}$。

2. 如果存在非零向量 $x$ 使得 $Ax = \lambda x$，则 $\lambda$ 是矩阵 $A$ 的一个特征值。

3. 特征向量不唯一。特征向量的任意常数倍也是特征向量。

4. $A$ 是实矩阵，依然可能存在复特征值。

5. 特征多项式（因此相应的也包括特征值）并不受基底改变的影响，因为对任何可逆矩阵 $Q$，都有
   $$
   \begin{aligned}
   \det(QAQ^{-1} - \lambda I) &= \det(QAQ^{-1} - \lambda QIQ^{-1}) \\
   &= \det\left(Q(AQ^{-1} - \lambda I Q^{-1}) \right)\\
   &= \det\left(Q(A - \lambda I)Q^{-1}\right)\\
   &= \det Q \det(A - \lambda I) \det Q^{-1}\\
   &= \det (A - \lambda I),
   \end{aligned}
   $$
   即有
   $$
   \sigma(QAQ^{-1}) = \sigma(A).
   $$

$\textbf{Remark 2.3.1.}$ Hermitian矩阵的特征值是实数。

$\textit{Proof.}$ Hermitian矩阵满足 $A^* = A$，因此我们有 $\lambda \|u\|^2 = \langle\lambda u, u\rangle = \langle Au, u\rangle = \langle u, A^*u\rangle = \langle u, Au\rangle = \langle u, \lambda u\rangle = \bar \lambda \|u\|^2,$ 即有 $\lambda  = \bar \lambda, \lambda \in \mathbb R. \square$

$\textbf{Definition 2.3.3.}$ 取 $\lambda$ 为矩阵 $A$ 的一个特征值。我们称向量空间
$$
E_\lambda  = \text{Ker}(A - \lambda I)  = \{x \in \mathbb C^n | Ax = \lambda x\}
$$
为关于特征值 $\lambda$ 的 **特征子空间（eigensubspace）** 。称向量空间
$$
F_\lambda = \bigcup_{k\geq 1} \text{Ker}(A - \lambda I)^k
$$
为关于特征值 $\lambda$ 的 **广义特征子空间（generalized eigensubspace）** 。

$\textbf{Remark.}$ 如果有 $x \in F_{\lambda}$，即 $(A - \lambda I)^k x = 0$，则显然有 $(A - \lambda I)^{k+1}x = 0$，即有 $x \in \text{Ker}(A - \lambda I)^{k+1}$。

$\textbf{Definition 2.3.4.}$ 让 $P(X) = \sum_{i=0}^d a_iX^i$ 是定义在 $\mathbb C$上的一个多项式。取矩阵 $A \in \mathcal M_n(\mathbb C)$，则相应的 **矩阵多项式（matrix polynomial）** $P(A)$ 被定义为 $P(A) = \sum_{i=0}^d a_iA^i$。

$\textbf{Lemma 2.3.1.}$ 如果 $Ax = \lambda x, x \neq 0$，那么对任意的多项式 $P(X)$，有 $P(A)x = P(\lambda)x$。换句话说，如果 $\lambda$ 是矩阵 $A$ 的一个特征值，则 $P(\lambda)$ 是矩阵 $P(A)$ 的一个特征值。

$\textbf{Theorem 2.3.1(Cayley-Hamilton).}$ 让 $P_A(\lambda) = \det(A - \lambda I)$ 为矩阵 $A$ 的特征多项式，那么我们有
$$
P_A(A) = 0.
$$
$\textbf{Remark 2.3.3.}$ The Cayley–Hamilton theorem shows that the smallest-degree possible for a polynomial that vanishes at $A$ is less than or equal to $n$. This smallest degree may be strictly less than $n$. We call the smallest-degree polynomial that vanishes at $A$ and whose highest-degree term has coefficient 1 the minimal polynomial of $A$.

$\textbf{Theorem 2.3.2(Spectral decomposition).}$ 考虑矩阵 $A \in \mathcal M_n(\mathbb C)$，其有 $p$ 个不同的特征值 $(\lambda_1, \cdots, \lambda_p), 1 \leq p \leq n$，分别的代数重数为 $n_1, \cdots, n_p, 1 \leq n_i \leq n, \sum_{i=1}^p n_i = n$。那么，它的广义特征子空间满足
$$
\mathbb C^n = \oplus_{i=1}^p F_{\lambda_i}, F_{\lambda_i} = \text{Ker}(A - \lambda_iI)^{n_i}, \dim F_{\lambda_i} = n_i,
$$
其中符号 $\oplus$ 表示子空间的直和。更准确的说，$\mathbb C^n = \oplus_{i=1}^p F_{\lambda_i}$ 代表任何向量 $x \in \mathbb C^n$ 可以被唯一分解为 $x = \sum_{i=1}^p x^i, x^i \in F_{\lambda_i}$。



## 四、矩阵的三角化

对角矩阵，上三角矩阵，下三角矩阵，是比较简单的矩阵形式。Reducing a matrix is the process of transforming it by a change of basis into one of these particular forms.

$\textbf{Definition 2.4.1.}$ 矩阵 $A \in \mathcal M_n(\mathbb C)$ 可以被化为三角形式（对角形式），或者说矩阵 $A$ 可以被三角化（对角化），如果存在一个可逆矩阵 $P$ 和一个三角矩阵 $T$（对角矩阵 $D$），使得
$$
A = PTP^{-1} (A = PDP^{-1}).
$$
$\textbf{Remark 2.4.1.}$ 我们称矩阵 $A$ 和 $T$ （$D$）是 **相似的（similar）** ：they correspond to the same linear transformation expressed in two different bases, and $P$ is the matrix of this change of basis. 根据相似的定义，我们有 $PA = PT \quad  (PA = PD)$。

> 直观地，我们拿二维做举例，假设有
> $$
> I x = x_1 \vec e_1 + x_2 \vec e_2 = \left[\begin{matrix}
> 1 & 0 \\
> 0 & 1
> \end{matrix}\right]
> \left[\begin{matrix}
> x_1 \\
> x_2
> \end{matrix}\right] = 
> \left[\begin{matrix}
> b_{11} & b_{12} \\
> b_{21} & b_{22}
> \end{matrix}\right]
> \left[\begin{matrix}
> y_1 \\
> y_2
> \end{matrix}\right] = y_1 \vec b_1 + y_2 \vec b_2 = By,
> $$
> 其中
> $$
> \vec e_1 = \left[\begin{matrix}
> 1 \\
> 0
> \end{matrix}\right],
> \vec e_2 = \left[\begin{matrix}
> 0 \\
> 1
> \end{matrix}\right],
> \vec b_1 = \left[\begin{matrix}
> b_{11} \\
> b_{21}
> \end{matrix}\right],
> \vec b_2 = \left[\begin{matrix}
> b_{21} \\
> b_{22}
> \end{matrix}\right].
> $$
> 我们称 $x = (x_1, x_2)$ 是在（单位）基向量 $\{\vec e_1, \vec e_2\}$ 下的坐标，称 $y = (y_1, y_2)$ 是在基向量 $\{\vec b_1, \vec b_2\}$ 下的坐标。因此，$x = By$，矩阵 $B$ 即为一个转换基底的（线性）变换。

如果 $A$ 可以被化为对角形式或者三角形式，那么它的特征值 $(\lambda_1, \cdots, \lambda_n)$ 以对应代数重数为重复次数，出现在 $D$ 或 $T$ 的对角线上，即有
$$
D=\left(\begin{array}{cc}
\lambda_{1} & & 0 \\
& \ddots & \\
0 & & \lambda_{n}
\end{array}\right) \quad \text { or } \quad T=\left(\begin{array}{ccc}
\lambda_{1} & \ldots & x \\
& \ddots & \vdots \\
0 & & \lambda_{n}
\end{array}\right),
$$
且 $A$ 的特征多项式可被表示为
$$
P(\lambda) = \det(A - \lambda I) = \prod_{i=1}^n(\lambda_i - \lambda).
$$
$\textit{Proof.}$ 

证明分为几个部分。

- 首先我们证明，上三角矩阵（下三角矩阵）的特征值即为对角线上的元素。（特别指出，对角矩阵是三角矩阵的一种特殊情况，所以也适用）

  对上三角矩阵 $T$（下三角矩阵同理），它的特征多项式为 $\det(T - \lambda I)$。矩阵 $T - \lambda I$ 同样为上三角矩阵，我们知道三角矩阵的行列式为对角线元素的乘积，而其对角线元素为 $(T - \lambda I)_{ii} = t_{ii} - \lambda$，因此有 $\det(T - \lambda I) = \prod_i (t_{ii} - \lambda) = 0$，即可看出 $T$ 的对角线元素 $t_{ii}$ 是矩阵 $T$ 的特征值。

- 其次证明，相似矩阵拥有相同的特征值。

  对相似矩阵 $A$ 和 $T$，假设 $\lambda$ 为 $A$ 的一个特征值，则对向量 $x$ 有 $Ax = \lambda x$；同时又有 $PA = PT$，因此有 $PAx = P \lambda x = PTx$，因此即得 $\lambda x = Tx$，说明 $\lambda$ 同样是 $T$ 的特征值。


综合上述两条结论，我们可知矩阵 $A$ 与矩阵 $T$（$D$）有着相同的特征值，且特征值即为矩阵 $T$（$D$）的对角线。

$\square$

$\textbf{Remark.}$ 如果矩阵 $A \in \mathcal M_n(\mathbb C)$ 可以被对角化，即存在可逆矩阵 $P$ 使得 $A = PDP^{-1}$，其中 $D = \text{diag}\{\lambda_i\}$，此时矩阵 $P$ 的列向量必为特征向量。这是因为，我们可以得到 $AP = PD$，即 $[Ap_1|\cdots | Ap_n] = [\lambda_1p_1|\cdots|\lambda_np_n]$，即有 $Ap_i = \lambda_ip_i$，其中 $p_i$ 为矩阵 $P$ 的第 $i$ 列向量。

$\textbf{Proposition 2.4.1.}$ 所有矩阵 $A \in \mathcal M_n(\mathbb C)$ 都可以被三角化（化为一个三角形式）。

$\textit{Proof.}$ 待补 $\square$

$\textbf{Remark 2.4.2.}$ 如果 $A$ 是实矩阵，上述结论依然成立，但 $T$ 和 $P$ 也许是复矩阵。例如，矩阵
$$
A = \left[\begin{matrix}
0 & -1\\
1 & 0
\end{matrix}\right]
$$
的特征值和特征向量都是复的。

<br>

我们已经知道所有方阵都可以被三角化。下面这个定理的目的是进一步证明，这一过程也许可以通过用一个正交基底变换来完成。

$\textbf{Theorem 2.4.1(Schur Factorization).}$ 对任何矩阵 $A \in \mathcal M_n(\mathbb C)$，存在一个酉矩阵 $U$（即有 $U^{-1} = U^*$），使得 $U^{-1}AU$ 是三角矩阵。这一定理也被称为Schur decomposition，即矩阵 $A$ 可以被分解为 $A = UTU^*$，其中 $T$ 为三角矩阵。

$\textit{Proof.}$ 待补 $\square$



## 五、矩阵对角化

$\textbf{Proposition 2.5.1.}$ 取矩阵 $A \in \mathcal M_n(\mathbb C)$，其有一组不同的特征值 $(\lambda_1, \cdots, \lambda_p), 1\leq p \leq n$，我们称矩阵 $A$ 是 **可对角化的（diagonalizable）** ，当且仅当
$$
\mathbb C^n = \operatorname{\oplus}_{i=1}\limits^p E_{\lambda_i},
$$
或等价地，当且仅当 $F_{\lambda_i} = E_{\lambda_i}, 1 \leq i \leq p$。

$\textit{Proof.}$ 待补 $\square$

通常来说，并不是所有的矩阵都是可对角化的，我们并不能总结出一个可对角化矩阵的通用形式。然而，如果我们希望一个矩阵可以通过由正交特征向量构成的基底来对角化，此时我们发现这类矩阵即为正规矩阵，即有 $AA^* = A^*A$。

$\textbf{Theorem 2.5.1(Diagonalization).}$ 取矩阵 $A \in \mathcal M_n(\mathbb C)$，$A$ 是正规矩阵（即有 $AA^* = A^*A$），当且仅当存在一个酉矩阵 $U$（即有 $U^{-1} = U^*$），使得
$$
A = U \text{diag}(\lambda_1, \cdots, \lambda_n)U^{-1},
$$
其中 $(\lambda_1, \cdots, \lambda_n)$ 为矩阵 $A$ 的特征值。

$\textit{Proof.}$ 待补 $\square$

$\textbf{Remark 2.5.1.}$ 存在可对角化矩阵，但并不是通过正交基底对角化，且不是正规矩阵。例如，矩阵
$$
A = \left[
\begin{matrix}
-1 & 2\\
0 & 1
\end{matrix}\right]
$$
不是正规矩阵，但它可以通过以特征向量为基的矩阵（不是正交基）来对角化：
$$
A = PDP^{-1} = \left(
\begin{matrix}
1 & \frac{1}{\sqrt{2}} \\
0 & \frac{1}{\sqrt{2}}
\end{matrix}\right)
\left(
\begin{matrix}
-1 & 0 \\
0 & 1
\end{matrix}\right)
\left(
\begin{matrix}
1 & -1 \\
0& \sqrt{2}
\end{matrix}\right).
$$
$\textbf{Theorem 2.5.2.}$ 取矩阵 $A \in \mathcal M_n(\mathbb C)$，$A$ 是自伴随的，或者说 $A$ 是Hermitian的（即有 $A = A^*$），当且仅当它可以被它的实特征值对应的正交特征向量对角化，换句话说，存在一个酉矩阵 $U$，使得
$$
A = U \text{diag}(\lambda_1, \cdots, \lambda_n)U^{-1}, \lambda_i \in \mathbb R.
$$
我们取 $(u_i)_{1 \leq i \leq n}$ 为 $U$ 的列向量，则 $A$ 可被分解为 $A = \sum_{i=1}^n \lambda_iu_iu_i^*$。

$\textit{Proof.}$ 待补 $\square$

$\textbf{Corollary 2.5.1.}$ 取矩阵 $A \in \mathcal M_n(\mathbb C)$，$A$ 是实对称的（即有 $A = A^T$），当且仅当存在一个正交矩阵 $Q$，使得
$$
A = Q \text{diag}(\lambda_1, \cdots, \lambda_n)Q^{-1},
$$
其中 $\lambda_1, \cdots, \lambda_n \in \mathbb R$ 为矩阵 $A$ 的特征值。

$\textbf{Definition.}$ 对Hermitian矩阵 $A \in \mathcal M_n(\mathbb C)$，如果它的特征值均严格大于$0$，则我们称它是 **正定的（positive definite）** ；如果它的特征值均非负，则我们称它是 **半正定的或正半定的（semipositive definite or positive semidefinite）** 。



## 六、Min-Max Principle

Min-Max principle，或者说Courant-Fisher principle，使得我们可以通过一个优化过程来取得Hermitian矩阵的特征值。

$\textbf{Definition 2.6.1.}$ 取Hermitian矩阵 $A \in \mathcal M_n(\mathbb C)$，我们称函数
$$
R_A(x) = \frac{\langle Ax, x\rangle}{\langle x, x\rangle}
$$
是矩阵 $A$ 的 **Rayleigh商（Rayleigh quotient）** ，它是 $\mathbb C^n \setminus \{0\} \mapsto \mathbb R$ 的：对任意向量 $x \in \mathbb C^n$，有 $\langle Ax, x\rangle = \langle x, A^*x\rangle = \langle x, Ax\rangle = \overline{\langle Ax, x\rangle}$，即说明 $\langle Ax, x\rangle$ 是实的，即通过Rayleigh商得到的结果是实数。

$\textbf{Theorem 2.6.1.}$ 取Hermitian矩阵 $A \in \mathcal M_n(\mathbb C)$，我们用 $\lambda_1$ 表示矩阵 $A$ 最小的特征值，则 $\lambda_1$ 满足
$$
\lambda_1 = \min_{x \in \mathbb C^n, x\neq 0} R_A(x) = \min_{x \in \mathbb C^n, \|x\|=1} \langle Ax, x\rangle,
$$
且两个优化问题的最小值，都在非零特征向量 $e_1 \neq 0$ 处取得（至少存在一个这样的非零特征向量），即有 $Ae_1 = \lambda_1 e_1$。

$\textit{Proof.}$ 待补 $\square$

$\textbf{Remark 2.6.1.}$ 同样的结论对最大特征值 $\lambda_n$ 也成立。即取Hermitian矩阵 $A \in \mathcal M_n(\mathbb C)$，我们用 $\lambda_n$ 表示矩阵 $A$ 最大的特征值，则 $\lambda_n$ 满足
$$
\lambda_n = \max_{x \in \mathbb C^n, x\neq 0} R_A(x) = \max_{x \in \mathbb C^n, \|x\|=1} \langle Ax, x\rangle,
$$
且两个优化问题的最大值，都在非零特征向量 $e_n \neq 0$ 处取得（至少存在一个这样的非零特征向量），即有 $Ae_n = \lambda_n e_n$。

$\textbf{Proposition 2.6.1.}$ 取Hermitian矩阵 $A \in \mathcal M_n(\mathbb C)$，它的特征值为 $\lambda_1 \leq \cdots \leq \lambda_n$。对 $i \in \{1, \cdots, n\}$，我们有
$$
\lambda_i = \min_{x\perp \text{span}\{e_1, \cdots, e_{i-1}\}}R_A(x) = \max_{x\perp \text{span}\{e_{i+1}, \cdots, e_n\}}R_A(x),
$$
其中 $(e_1, \cdots, e_n)$ 是矩阵 $A$ 特征值 $(\lambda_1, \cdots, \lambda_n)$ 对应的特征向量；$x \perp W$ 代表对子空间 $W \sub \mathbb C^n$，对任意的 $\omega \in W$，都有 $\langle x, \omega\rangle = 0$。$x \perp W \Longleftrightarrow x \in W^{\perp} = \{x: \langle x, \omega \rangle = 0, \forall \omega \in W\}$。

$\textbf{Theorem 2.6.2(Courant-Fisher or min-max).}$ 取Hermitian矩阵 $A \in \mathcal M_n(\mathbb C)$，它的特征值为 $\lambda_1 \leq \cdots \leq \lambda_n$。对 $i \in \{1, \cdots, n\}$，我们有
$$
\begin{aligned}
\lambda_i
&= \min_{\left(a_{1}, \cdots, a_{n-i}\right) \in \mathbb{C}^{n}} \quad \max_{x \perp \text{span}\left\{a_{1}, \cdots, a_{n-i}\right\}} R_{A}(x) \\
&= \max_{\left(a_{1}, \cdots, a_{i-1}\right) \in \mathbb{C}^{n}} \quad \max_{x \perp \text{span}\left\{a_{1}, \cdots, a_{i-1}\right\}} R_{A}(x).
\end{aligned}
$$
$\textit{Proof.}$ 待补 $\square$



## 七、矩阵的奇异值

在本章节中，我们考虑来自 $\mathcal M_{m,n}(\mathbb C)$ 的矩阵，即讨论的矩阵不一定要是方阵。

在定义奇异值前，我们先介绍一条引理。

$\textbf{Lemma 2.7.1.}$ 对任意矩阵 $A \in \mathcal M_{m,n}(\mathbb C)$，矩阵 $A^*A$ 是Hermitian的，且有实非负特征值。或者说，矩阵 $A^*A$ 是半正定的。

$\textit{Proof.}$ 显然 $A^*A$ 是 $n$ 阶Hermitian矩阵，因此它的特征值都是实数。令 $\lambda$ 为矩阵 $A^*A$ 的一个特征值，取 $x$ 为 $\lambda$ 对应的特征向量，则有
$$
\lambda = \frac{\langle A^*Ax, x \rangle}{\langle x, x \rangle} = \frac{\langle Ax, Ax \rangle}{\langle x, x \rangle} = \frac{\|Ax\|^2}{\|x\|^2} \in \mathbb R^+,
$$
即所有特征值 $\lambda$ 均非负。$\square$

$\textbf{Definition 2.7.1.}$ 对任意矩阵 $A \in \mathcal M_{m,n}(\mathbb C)$，它的 **奇异值（singular value）** 被定义为矩阵 $A^*A$ 的 $n$ 个特征值的非负平方根。由引理2.7.1可知，奇异值一定是实数。

下一条引理会说明，矩阵 $A^*A$ 和矩阵 $AA^*$ 有着相同的非零特征值。

$\textbf{Lemma 2.7.2.}$ 取矩阵 $A \in \mathcal M_{m,n}(\mathbb C), B \in \mathcal M_{n, m}(\mathbb C)$，则矩阵 $AB$ 与矩阵 $BA$ 的非零特征值相同。

$\textit{Proof.}$ 取 $\lambda$ 为矩阵$AB$ 的一个特征值，$u$ 是该特征值对应的非零特征向量，即有 $ABu = \lambda u$。如果 $u \in \text{Ker}(B) = \{x|Bx=0, x \in \mathbb C^m\}$，我们可以推出 $\lambda u = A(Bu) = 0$，且由于 $u \neq 0$，因此有 $\lambda = 0$；如果 $\lambda \neq 0$，那么 $u \notin \text{Ker}(B)$，我们可以计算得 $BA(Bu) = \lambda(Bu)$，其中 $Bu \neq 0$，即 $\lambda$ 也是矩阵 $BA$ 的特征值。$\square$

$\textbf{Proposition 2.7.1.}$ 对正规矩阵 $A \in \mathcal M_{n}(\mathbb C)$，它的奇异值即为它特征值的模，即奇异值构成的集合为 $\{|\lambda|: \lambda \in \sigma(A)\}$。

$\textit{Proof.}$ 矩阵 $A$ 是正规矩阵，因此存在一个酉矩阵 $U$，使得 $A = UDU^*$，其中 $D = \text{diag}(\lambda_i)$，因此有 $A^*A = (UDU^*)^*(UDU^*) = UD^*DU^*$，因此矩阵 $A^*A$ 和矩阵 $D^*D$ 是相似的，它们有相同的特征值；又有 $D^*D = \text{diag}\{|\lambda_i|^2\}$，因此 $\sigma(D^*D) = \{|\lambda_1|^2, \cdots, |\lambda_n|^2\}$，所以矩阵 $A^*A$ 的特征值也为 $|\lambda_i|^2$，即矩阵 $A$ 的奇异值为 $|\lambda_i|$。$\square$

$\textbf{Remark 2.7.2.}$ 对正规矩阵 $A \in \mathcal M_{n}(\mathbb C)$，它的谱半径即为它最大的奇异值。回顾谱半径：$\varrho(A) = \{|\lambda_i|, \text{where }\lambda_i \in \sigma(A), i = 1,\cdots, n\}$。

<br>

$\textbf{Theorem 2.7.1(SVD factorization).}$ 对任意矩阵 $A \in \mathcal M_{m,n}(\mathbb C)$，它有 $r$ 个正奇异值，即 $\mu_1 \geq \mu_2 \geq \cdots \geq \mu_r > 0$。存在两个酉矩阵 $U \in \mathcal M_n(\mathbb C), V \in \mathcal M_m(\mathbb C)$，一个对角矩阵 $\tilde \Sigma \in \mathcal M_{m,n}(\mathbb R)$，使得
$$
A = V\tilde \Sigma U^*, 
\tilde \Sigma = \left(
\begin{matrix}
\Sigma & 0 \\
0 & 0
\end{matrix}\right),
$$
其中 $\Sigma = \text{diag}(\mu_1, \cdots, \mu_r)$。

$\textit{Proof.}$ 待补 $\square$

$\textbf{Remark.}$

- 对矩阵 $A \in \mathcal M_{m,n}(\mathbb R)$，奇异值分解中的 $U$ 和 $V$ 也是实矩阵。

- 对矩阵 $A = V\Sigma U^T \in \mathcal M_{m,n}(\mathbb R)$，将其作用于单位球 $S^{n-1} = \{x \in \mathbb R^n: \|x\|=1\}$ 即 $AS^{n-1}$，会得到一个椭球（ellipsoid）。

  $U$ 为正交矩阵，因此不改变形状；$\Sigma$ 为对角矩阵，起到squeeze and scratch的作用；$V$ 为正交矩阵，因此也只起到旋转的作用。

- 对一个矩阵做SVD分解并不等价于对角化该矩阵，因为 $U$ 和 $V$ 对应的是不同基底。

- 我们自然会想，$U$ 和 $V$ 究竟有多少种可能呢？

  我们做运算 $A^*A = U(\Sigma^T\Sigma)U^* = U(\Sigma^T\Sigma)U^{-1}$，即 $A^*A$ 可对角化，由于 $\Sigma^T\Sigma$ 为对角矩阵，因此 $U$ 必由 $A^*A$ 的特征向量构成；同理，$AA^* = V(\Sigma \Sigma^T)V^{-1}$，即 $V$ 必由 $AA^*$ 的特征向量构成。

$\textbf{Definition2.7.2(Moore-Penrose).}$ 对任意矩阵 $A \in \mathcal M_{m,n}(\mathbb C)$，让 $A = V \tilde \Sigma U^*$ 为它的奇异值分解，我们称矩阵 $A^\dagger =U\tilde \Sigma^\dagger V^* \in \mathcal M_{n,m}(\mathbb C)$ 为矩阵 $A$ 的 **伪逆矩阵（pseudoinverse matrix）** ，其中
$$
\tilde \Sigma^\dagger = \left(\begin{matrix}
\Sigma^{-1} & 0 \\
0 & 0
\end{matrix}\right)
\in \mathcal M_{n,m}(\mathbb R).
$$
$\textbf{Remark.}$ 对任意矩阵 $A \in \mathcal M_{m,n}(\mathbb C)$，如果它的秩为 $r = n \leq m$，则它的伪逆为
$$
A^\dagger = (A^*A)^{-1}A^*.
$$
特别地，如果 $A$ 是非奇异矩阵（$r = n = m$），我们即有 $A^\dagger A = AA^\dagger = I_n$，即此时 $A^\dagger = A^{-1}$。从这个角度来看，伪逆矩阵就是逆矩阵的广义推广。

$\textbf{Remark 2.7.7(Moore-Penrose conditions).}$ 可以被证明，对任意矩阵 $A \in \mathcal M_{m,n}(\mathbb C)$，它的伪逆矩阵 $X$ 是满足下列条件的唯一矩阵：
$$
AXA = A, \quad XAX = X, \quad XA = (XA)^*, \quad AX = (AX)^*.
$$
